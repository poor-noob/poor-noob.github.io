# 第一周实习进度及成果

<details>
<summary>
<B>
<font color=#0969DA>每日总结(已发微信)</font>
</B>
</summary>

#### 7.15
1、VScode配置通义灵码；
2、从Hugging Face下载Gemma，通过LM Studio进行部署后尝试使用；
3、学习Typescript和Langchain，通过Python和Typescript链接ChatGPT API；
4、初步学习使用Vite，建立了一个简单的页面

#### 7.16
1、继续学习Type Script，向Langchain导入本地大模型；
2、尝试用多个大模型制作基于Vite的登录页面，包含用户名与密码的验证功能

#### 7.17
1、学习Typescript和Langchain，构建本地知识库；
2、向知识库导入Typescript和Vite相关文档，引导ChatGLM基于该知识库实现登录页面

#### 7.18
1、学习Typescript和Langchain；
2、使用LM Studio启动本地服务器，通过链接本地端口调用其中的模型

#### 7.19
1、学习Typescript和Transformers库的使用；
2、初步学习提示词的构建，编写了一个简单的提示词模板
</details>

**摘要：** 7.15~7.19共计五天时间，主要做的是熟悉语言和框架，并在完成基础的学习后进行初步实践。本报告略写学习与了解的过程而详写初步运用的过程，且会附上学习文档、视频的来源与编写的代码文件，同时展示代码的运行效果。

**关键词：Langchain，Typescript，Python，LLM，提示词**

### 1、我的首个程序
本周一直都有在学习Typescript，但是因为网上关于Typescript调用Langchain的教学不像Python的那么多，可参考的主要是官方使用文档[^1]、部分视频资源[^2]以及AI，且在过去的学习中，我更多接触的也是Python。虽然这并不意味着我将会逃避使用Typescript，但在刚开始构建基于Langchain的相关项目时，我还是选择使用了Python作为编译语言。我尝试编写的首个相关程序如下：
```python
import requests

def chat(prompt, history):
    resp = requests.post(
        url='http://127.0.0.1:8000',
        json={"prompt":prompt,"history":history},
        headers={"Content-Type": "application/json;charset=utf-8"}
    )
    return resp.json()['response'], resp.json()['history']

history = []
while True:
    response, history = chat(input("聊点什么吧："), history)
    print('ChatGLM：', response)
```
这段代码实现了接收用户输入的文本和对话历史，让运行于本地的服务处理后，返回输出并储存对话记录的功能。当然，它需要搭配相关的本地大语言模型（ChatGLM、Llama、Gemma等）使用，且通过某端口运行后都能套进去。

### 2、进一步学习
显而易见，第一部分程序的功能过于基础，和直接使用模型没什么两样，显然不能满足各类定制化任务需求。因此接下来我继续学习[^4]，嵌入了其他功能，部分代码如下：
```python
from langchain_community.document_loaders import DirectoryLoader, UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
def load_pdf_doc(directory = 'docs'):
    Dloader = DirectoryLoader(directory,loader_cls = UnstructuredFileLoader,use_multithreading=True)
    docs = Dloader.load()
    splitter = CharacterTextSplitter(chunk_size=1000,chunk_overlap=100)
    split_docs = splitter.split_documents(docs)
    return split_docs
```
这段代码通过调用langchain库定义了一个新函数，它能够读取本地文件夹中的非结构化文件，并将其切分成1000字符一个的小块（每块有100字重叠部分）。这样处理出来的数据对后续的文本处理与分析而言更方便。

对数据切片只是第一步，之后还涉及到嵌入、数据向量化、建立知识库、建立检索链等。篇幅所限，相关代码在以下文件中，其中注释由通义灵码撰写，其功能大致为：读取本地特定路径内的文件并进行相关处理，让ChatGLM能基于这些文档给出相应的回答。
[代码示例.zip](https://github.com/user-attachments/files/16328636/default.zip)

### 3、其他方向的学习
#### 3.1、Langchain方向
之后两天我没有继续研究本地知识库的构建，转而去学习了提示词模板的编写。相关代码如下：
```python
from langchain.prompts import PromptTemplate as PT
UserInputs=GetValidInputs()
Prompt_Template=PT.from_template("{adj}的{obj}叫{name}")
Formatted_Prompt=Prompt_Template.format(adj=UserInputs[0],obj=UserInputs[1],name=UserInputs[2])
print(Formatted_Prompt)
```
**\*其中GetValidInputs是我自己定义的一个函数，由于和langchain无关，此处不作说明。**
以上代码定义了一个提示词的模板，并允许用户输入模板中的三个变量。这样，输入给大语言模型的文本就不完全是用户自定义的，可能使AI输出的文本更规范等。

### 3.2、Typescript、Vite等
虽然这些方面的学习贯穿了整周，但是暂时都是偏向理论方向的学习。很抱歉，目前我唯一能拿得出手的也不过是一个由ChatGPT基于和Vite编写的登陆页面。

### 5、总结，以及之后的学习
总的来说，这一周下来我所学的内容并不算多。如果想要独立
*参考文档、视频等位于脚注处

[^1]:[Typescript教程](https://www.runoob.com/typescript/ts-tutorial.html)
[Typescript视频教程](https://www.bilibili.com/video/BV14Z4y1u7pi/)
[^2]:[Typescript+Langchain（构建网页的视频教程，很短）](https://www.bilibili.com/video/BV1th4y1n7jJ/)
[^3]:[OpenAI官网（申请ChatGPT的API接口，或直接使用）](https://openai.com/chatgpt/)
[通义官网（申请通义的API接口，或直接使用）](https://tongyi.aliyun.com/)
[^4]:[Langchain+ChatGLM构建本地知识库1](https://www.bilibili.com/video/BV1t8411y7fp/)
[Langchain+ChatGLM构建本地知识库2](https://www.bilibili.com/video/BV13M4y1e7cN/)

[LM Studio使用文档（LMS界面挺好懂，可以不看）](https://lmstudio.ai/docs/welcome)
[Langchain教学视频（简明易懂，能作为引入）](https://www.bilibili.com/video/BV1tw411k76M/)
[Hugging Face官网（下载各类大语言模型用）](https://huggingface.co/)
[Langchain使用文档（较繁琐但详细且官方）](https://python.langchain.com.cn/docs/)
[Vite使用文档（构建网页用，官方文档）](https://vitejs.cn/vite3-cn/guide/)
